{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`page 198`\n",
    "\n",
    "# Chapter 5\n",
    "\n",
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = sm.datasets.get_rdataset('Default', package='ISLR').data\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           default[Yes]   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 13 Feb 2019   Pseudo R-squ.:                  0.4594\n",
      "Time:                        10:52:22   Log-Likelihood:                -789.48\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "                                        LLR p-value:                4.541e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
      "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
      "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model \n",
    "y, X = dmatrices('default ~ income + balance', data=default, return_type='dataframe')\n",
    "\n",
    "# Fit the model\n",
    "model = sm.Logit(y.iloc[:,1:], X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.97'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Sklearn. I used different approach.\n",
    "def logistic_reg(X, y):\n",
    "    \"\"\" Take X and y and spits out validation set error rate. \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "    lrm = classifier.fit(X_train, y_train)\n",
    "    return \"Accuracy: {:.2f}\".format(lrm.score(X_test, y_test)) #incorrect. \".score()\" returns R2, NOT accuracy\n",
    "\n",
    "logistic_reg(default.iloc[:,2:], default['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali Sina\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.97'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explicit encoding\n",
    "enc = LabelEncoder()\n",
    "default['default'] = enc.fit_transform(default['default'])\n",
    "default['student'] = enc.fit_transform(default['student'])\n",
    "\n",
    "# Including the \"student\" variable\n",
    "logistic_reg(default.iloc[:,1:], default['default'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Skipped exercise 6\n",
    "***\n",
    "\n",
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly = sm.datasets.get_rdataset('Weekly', package='ISLR').data\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683297\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          Direction[Up]   No. Observations:                 1089\n",
      "Model:                          Logit   Df Residuals:                     1086\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 13 Feb 2019   Pseudo R-squ.:                0.005335\n",
      "Time:                        10:52:35   Log-Likelihood:                -744.11\n",
      "converged:                       True   LL-Null:                       -748.10\n",
      "                                        LLR p-value:                   0.01848\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2212      0.061      3.599      0.000       0.101       0.342\n",
      "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
      "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Using Patsy design matrix\n",
    "y, X = dmatrices('Direction ~ Lag1 + Lag2', data=weekly, return_type='dataframe')\n",
    "\n",
    "# Fit to logistic regression model\n",
    "glm_fitted = sm.Logit(y.iloc[:,1], X).fit()\n",
    "\n",
    "print(glm_fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    False\n",
       "Name: 0, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dummy dataframe of model predictions\n",
    "preds = pd.DataFrame(np.zeros(shape=(1089, 1)), columns=['label'])\n",
    "\n",
    "# Change into binary value of \"UP\" (1) if predictions (pobability) is > 0.5\n",
    "preds.iloc[glm_fitted.predict() > 0.5] = 1\n",
    "\n",
    "# Compare with first observation\n",
    "preds.iloc[0] == y.iloc[:,1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Skipped the LOOCV part. It could be easily done with the Sklearn's LeaveOneOut() function\n",
    "***\n",
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "X = np.random.normal(size=100)\n",
    "y = X - 2*X**2 + np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(X, y, fit_reg=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Leave-One-Out Cross Validation**\n",
    "\n",
    "According to [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html), LOOCV is the same as `KFold(n_splits)`, which is obvious. So I'll just use KFold with `n_splits=n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.661427583408592, -0.8511228571299867, -0.8669069848185395, -0.8888056674096625]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for porder in np.arange(1, 5):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=porder)), ('linreg', LinearRegression())])\n",
    "    k_fold = KFold(n_splits=len(X))\n",
    "    test = cross_val_score(model, X.reshape(-1, 1), y, cv=k_fold, scoring='neg_mean_squared_error')\n",
    "    scores.append(np.mean(test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, I also do other kinds of validation:\n",
    "\n",
    "#### **KFold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.76541452443797, 0.8353562927606714, 0.8547916893406058, 0.8661035747304389]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for porder in np.arange(1, 5):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=porder)), ('linreg', LinearRegression())])\n",
    "    k_fold = KFold(n_splits=5)\n",
    "    test = cross_val_score(model, X.reshape(-1, 1), y, cv=k_fold, scoring='neg_mean_squared_error')\n",
    "    scores.append(np.mean(-test)) #negative sign because cross_val_score return negative vals\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Can use the following code to get a list of valid scorers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import SCORERS\n",
    "# sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bootstrap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650294576421797"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alpha(predictor, response, index):\n",
    "    X = predictor[index]\n",
    "    Y = response[index]\n",
    "    return (np.var(Y) - np.cov(X,Y)[0,1])/(np.var(X) + np.var(Y) - 2 * np.cov(X, Y)[0,1])\n",
    "\n",
    "alpha(predictor=X, response=y, index=np.arange(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.041\n",
      "Std dev: 0.077\n"
     ]
    }
   ],
   "source": [
    "def bootstrap(predictor, response, input_fun, iteration):\n",
    "    \"\"\" Records estimates of alpha and returns its mean and std dev.\"\"\"\n",
    "    data = np.vstack((response, predictor)).T\n",
    "    n = len(data)\n",
    "    idx = np.random.randint(0, n, (iteration, n))\n",
    "    stat = np.zeros(iteration)\n",
    "    for i in np.arange(len(idx)):\n",
    "        stat[i] = input_fun(data[:,0], data[:,1], idx[i])\n",
    "    \n",
    "    print('Mean: {:.3f}\\nStd dev: {:.3f}'.format(np.mean(stat), np.std(stat)))\n",
    "\n",
    "bootstrap(X, y, alpha, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap is used to assess the variabality of the coefficient estimates. In this case, bootstrap is estimated a coefficient estimate of 0.041 with `std dev = 0.077`, which is somewhat close to MSE obtained with KFold and LOO with higher degree polynomials.\n",
    "\n",
    "***\n",
    "\n",
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm    age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222     18.7   \n",
       "5  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222     18.7   \n",
       "6  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311     15.2   \n",
       "7  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311     15.2   \n",
       "8  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311     15.2   \n",
       "9  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311     15.2   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  \n",
       "5  394.12   5.21  28.7  \n",
       "6  395.60  12.43  22.9  \n",
       "7  396.90  19.15  27.1  \n",
       "8  386.63  29.93  16.5  \n",
       "9  386.71  17.10  18.9  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = sm.datasets.get_rdataset('Boston', package='MASS').data\n",
    "boston.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 22.532806324110698  | SE: 0.4084569346972867\n"
     ]
    }
   ],
   "source": [
    "print('Mean:', np.mean(boston['medv']), ' | SE:', np.std(boston['medv'])/np.sqrt(len(boston)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.528756916996052, 0.4078039336742418)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating with bootstrap. Not sure if this is the most \n",
    "# elegant solution. There are modules to help with this,\n",
    "# but I preferred creating my own solution\n",
    "\n",
    "def bootstrap(X, iters=1):\n",
    "    \"\"\" Estimating mu and SE with bootstrap method\"\"\"\n",
    "    \n",
    "    n = len(X)\n",
    "    \n",
    "    # Random n index numbers\n",
    "    idx = np.random.randint(0, n , (iters, n))\n",
    "    \n",
    "    # Stores n random samples, each of size n\n",
    "    samples = []\n",
    "    \n",
    "    # Stores means and std devs of each sample\n",
    "    means = []\n",
    "    std_devs = []\n",
    "    \n",
    "    # Computing for each sample\n",
    "    for i in range(0, len(idx)):\n",
    "        samples.append(X[idx[i]])\n",
    "        means.append(samples[i].mean())\n",
    "        std_devs.append(np.std(samples[i]))\n",
    "    \n",
    "    # Computing totals\n",
    "    total_mean = np.mean(means)\n",
    "    se = np.mean(std_devs)/np.sqrt(n)\n",
    "    \n",
    "    return total_mean, se\n",
    "\n",
    "bootstrap(boston['medv'], iters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap estimates are very close to true estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval: 21.725629830207655 23.356100999831877\n"
     ]
    }
   ],
   "source": [
    "results = bootstrap(boston['medv'], iters=1000)\n",
    "\n",
    "print('Confidence interval:', results[0]-2*results[1], results[0]+2*results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Skipped next parts because very similar to the one above. A way to improve `bootstrap` function is to give the functionality where the user can specify what test statistic they want to estimate.\n",
    "\n",
    "### $Fin$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
